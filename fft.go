// Modular FFT routines

package main

import (
	"fmt"
)

// FFT interface
type Fft interface {
	Fft([]uint64)
	InvFft([]uint64)
	BitReverse([]uint64)
	//	Name() string
	//	BitReversed() bool
}

type FftBasics struct {
	n     uint // number of 64bit digits in the arrays
	log_n uint8

	MOD_W    uint64
	MOD_INVW uint64
	root2    uint64
}

// Make tables for fft
func (f *FftBasics) Init(log_n uint8) {
	f.log_n = log_n
	f.n = uint(1) << f.log_n

	// An n-th root of unity can be generated by 7^(5*(p-1)/n) mod p.
	f.MOD_W = mod_pow(7, (MOD_P-1)/uint64(f.n))
	f.MOD_W = mod_pow(f.MOD_W, 5)
	f.MOD_INVW = mod_inv(f.MOD_W)

	if log_n != 0 && mod_pow(f.MOD_W, uint64(f.n-1)) == 1 {
		panic("Root of 1 is wrong: w ** (n-1) == 1")
	}
	if mod_pow(f.MOD_W, uint64(f.n)) != 1 {
		panic("Root of 1 is wrong: w ** n != 1")
	}
}

// Bit reverse - slow
func (f *FftBasics) BitReverse(x []uint64) {
	for i := uint(0); i < f.n; i++ {
		m := uint(0)

		for j := uint8(0); j < f.log_n; j++ {
			m |= ((i >> j) & 1) << (f.log_n - j - 1)
		}

		if m > i {
			x[i], x[m] = x[m], x[i]
		}
	}
}

// ------------------------------------------------------------

// A slow O(n^2) fft for testing purposes
type FftSlow struct {
	FftBasics
	t []uint64
}

// Check interface is satisfied
var _ Fft = (*FftSlow)(nil)

func NewFftSlow(log_n uint8) *FftSlow {
	f := &FftSlow{}
	f.Init(log_n)
	f.t = make([]uint64, f.n)
	return f
}

func (f *FftSlow) _fft_slow(x []uint64, inverse bool) {
	var w uint64 = f.MOD_W
	if inverse {
		w = f.MOD_INVW
	}
	wk := uint64(1)

	for k := uint(0); k < f.n; k++ {
		sum := uint64(0)
		wj := uint64(1)
		// printf("wk(%02i) = %s\n", k, mod_string(wk));
		for j := uint(0); j < f.n; j++ {
			// printf("  wj(%02i) = %s\n", k, mod_string(wj));
			sum = mod_add(sum, mod_mul(wj, x[j]))
			wj = mod_mul(wj, wk)
		}
		f.t[k] = sum
		wk = mod_mul(wk, w)
	}

	copy(x, f.t)
}

// A slow O(n^2) fft
func (f *FftSlow) Fft(x []uint64) {
	f._fft_slow(x, false)
}

// A slow O(n^2) inverse fft
func (f *FftSlow) InvFft(x []uint64) {
	f._fft_slow(x, true)
}

// ------------------------------------------------------------

// A fastish bit reversed O(n log n) FFT
type FftFastish struct {
	FftBasics
}

// Check interface is satisfied
var _ Fft = (*FftFastish)(nil)

func NewFftFastish(log_n uint8) *FftFastish {
	f := &FftFastish{}
	f.Init(log_n)
	return f
}

// A fastish O(n log n) FFT
//
// Output is bit-reversed
func (f *FftFastish) Fft(x []uint64) {
	var d uint64 = f.MOD_W

	for k := f.log_n; k >= 1; k-- {
		m := uint(1) << k
		c := m >> 1
		var w uint64 = 1
		for j := uint(0); j < c; j++ {
			for r := uint(0); r < f.n; r += m {
				a := r + j
				b := a + c
				u := x[a]
				v := x[b]
				x[a] = mod_add(u, v)
				x[b] = mod_mul(mod_sub(u, v), w)
			}
			w = mod_mul(w, d)
		}
		d = mod_mul(d, d)
	}
}

// A fastish O(n log n) Inverse FFT
//
// Input should be bit-reversed
func (f *FftFastish) InvFft(x []uint64) {
	for k := uint8(1); k <= f.log_n; k++ {
		m := uint(1) << k
		c := m >> 1
		z := uint64(1 << (f.log_n - k))
		d := mod_pow(f.MOD_INVW, z)
		w := uint64(1)
		for j := uint(0); j < c; j++ {
			for r := uint(0); r < f.n; r += m {
				a := r + j
				b := a + c
				u := x[a]
				v := mod_mul(w, x[b])
				x[a] = mod_add(u, v)
				x[b] = mod_sub(u, v)
			}
			w = mod_mul(w, d)
		}
	}
}

// ------------------------------------------------------------

// A fastish bit reversed O(n log n) FFT
type FftShift struct {
	FftBasics
}

// Check interface is satisfied
var _ Fft = (*FftShift)(nil)

func NewFftShift(log_n uint8) *FftShift {
	f := &FftShift{}
	f.Init(log_n)
	return f
}

// A O(n log n) FFT which uses shifts only
//
// Can only be use for log_n = 1..6
//
// Output is bit-reversed
func (f *FftShift) Fft(x []uint64) {
	d := uint8(192 / f.n)
	for k := f.log_n; k >= 1; k-- {
		m := uint(1) << k
		c := m >> 1
		var w uint8 = 0
		for j := uint(0); j < c; j++ {
			for r := uint(0); r < f.n; r += m {
				a := r + j
				b := a + c
				u := x[a]
				v := x[b]
				x[a] = mod_add(u, v)
				x[b] = mod_shift(mod_sub(u, v), w)
			}
			w += d
		}
		d <<= 1
	}
}

// A O(n log n) Inverse FFT which uses shifts only
//
// Can only be use for log_n = 1..6
//
// Input should be bit-reversed
func (f *FftShift) InvFft(x []uint64) {
	d := uint8(192/f.n) << (f.log_n - 1)
	for k := uint8(1); k <= f.log_n; k++ {
		m := uint(1) << k
		c := m >> 1
		var w uint8 = 0
		for j := uint(0); j < c; j++ {
			for r := uint(0); r < f.n; r += m {
				a := r + j
				b := a + c
				u := x[a]
				v := mod_shift(x[b], 96-w)
				// Note that shifting by 96 is negate so negate butterfly
				x[a] = mod_sub(u, v)
				x[b] = mod_add(u, v)
			}
			w += d
		}
		d >>= 1
	}
}

// ------------------------------------------------------------

// A unrolled bit reversed O(n log n) FFT
type FftUnrolled struct {
	FftBasics
	fft    func(x []uint64)
	invfft func(x []uint64)
}

// Check interface is satisfied
var _ Fft = (*FftUnrolled)(nil)

func NewFftUnrolled(log_n uint8) *FftUnrolled {
	f := &FftUnrolled{}
	f.Init(log_n)
	switch log_n {
	case 0:
		f.fft = fft0
		f.invfft = invfft0
	case 1:
		f.fft = fft1
		f.invfft = invfft1
	case 2:
		f.fft = fft2
		f.invfft = invfft2
	case 3:
		f.fft = fft3
		f.invfft = invfft3
	case 4:
		f.fft = fft4
		f.invfft = invfft4
	case 5:
		f.fft = fft5
		f.invfft = invfft5
	case 6:
		f.fft = fft6
		f.invfft = invfft6
	case 7:
		f.fft = fft7
		f.invfft = invfft7
	case 8:
		f.fft = fft8
		f.invfft = invfft8
	case 9:
		f.fft = fft9
		f.invfft = invfft9
	case 10:
		f.fft = fft10
		f.invfft = invfft10
	default:
		panic(fmt.Sprintf("Don't have unrolled fft for log_n = %d", log_n))
	}
	return f
}

// A unrolled O(n log n) FFT
//
// Output is bit-reversed
func (f *FftUnrolled) Fft(x []uint64) {
	f.fft(x)
}

// A unrolled O(n log n) Inverse FFT
//
// Input should be bit-reversed
func (f *FftUnrolled) InvFft(x []uint64) {
	f.invfft(x)
}

// ------------------------------------------------------------

// A four step O(n log n) FFT
type FftFourStep struct {
	FftBasics
	log_rows    uint8
	log_cols    uint8
	rows        uint
	cols        uint
	twiddle     []uint64
	inv_twiddle []uint64
	scratch     []uint64
	col_fft     Fft
	row_fft     Fft
}

// Check interface is satisfied
var _ Fft = (*FftFourStep)(nil)

func NewFftFourStep(log_n uint8) *FftFourStep {
	f := &FftFourStep{}
	f.Init(log_n)

	f.log_rows = f.log_n / 2
	f.log_cols = f.log_n - f.log_rows
	f.rows = 1 << f.log_rows
	f.cols = 1 << f.log_cols
	f.row_fft = NewFftUnrolled(f.log_cols)
	f.col_fft = NewFftUnrolled(f.log_rows)
	// if f.log_cols <= 6 {
	// 	f.row_fft = NewFftShift(f.log_cols)
	// } else {
	// 	f.row_fft = NewFftFastish(f.log_cols)
	// }
	// if f.log_rows <= 6 {
	// 	f.col_fft = NewFftShift(f.log_rows)
	// } else {
	// 	f.col_fft = NewFftFastish(f.log_rows)
	// }

	// Make the twiddles
	ddw := f.MOD_W
	iddw := f.MOD_INVW
	dw := uint64(1)
	idw := uint64(1)
	p := 0
	f.twiddle = make([]uint64, f.n)
	f.inv_twiddle = make([]uint64, f.n)
	f.scratch = make([]uint64, f.n)
	for ix := uint(0); ix < f.cols; ix++ {
		w := uint64(1)
		iw := uint64(1)
		for iy := uint(0); iy < f.rows; iy++ {
			f.twiddle[p] = w
			f.inv_twiddle[p] = iw
			w = mod_mul(w, dw)
			iw = mod_mul(iw, idw)
			p++
		}
		dw = mod_mul(dw, ddw)
		idw = mod_mul(idw, iddw)
	}

	// bit reverse the twiddles
	// for i := uint(0); i < f.rows; i++ {
	// 	f.col_fft.BitReverse(f.twiddle[i<<f.log_rows : i<<f.log_rows+f.rows])
	// }
	// Transpose(f.inv_twiddle, f.scratch, f.log_cols, f.log_rows)
	// for i := uint(0); i < f.cols; i++ {
	// 	f.row_fft.BitReverse(f.inv_twiddle[i<<f.log_cols : i<<f.log_cols+f.cols])
	// }
	// Transpose(f.inv_twiddle, f.scratch, f.log_cols, f.log_rows)

	/* transpose the weighting arrays */
	// FIXME Transpose(f.digit_weight, f.scratch, f.log_cols, f.log_rows)
	// Transpose(f.digit_unweight, f.scratch, f.log_cols, f.log_rows)

	return f
}

// A O(n log n) FFT which uses shifts only
//
// Can only be use for log_n = 1..6
//
// Output is bit-reversed
func (f *FftFourStep) _Fft(x []uint64, inverse bool) {
	// FIXME why start and end transpose needed
	// because Baileys original FFT which this follows is based on
	// fortran and column major addressing where as we are using row
	// major addressing

	// FIXME get rid of bit reverse?

	// FIXME make non square work

	/* transpose the matrix */
	x, f.scratch = Transpose(x, f.scratch, f.log_cols, f.log_rows)

	/* fft down the columns */
	for iy := uint(0); iy < f.cols; iy++ {
		p := x[iy<<f.log_rows : (iy+1)<<f.log_rows]
		if inverse {
			f.col_fft.BitReverse(p)
			f.col_fft.InvFft(p)
		} else {
			f.col_fft.Fft(p)
			f.col_fft.BitReverse(p)
		}
		// FIXME should multiply by twiddle here row by row while it is in cache
	}

	/* multiply by constant */
	if inverse {
		mod_vector_mul(f.n, x, f.inv_twiddle)
	} else {
		mod_vector_mul(f.n, x, f.twiddle)
	}

	/* transpose the matrix */
	x, f.scratch = Transpose(x, f.scratch, f.log_rows, f.log_cols)

	/* fft down the rows */
	for iy := uint(0); iy < f.rows; iy++ {
		p := x[iy<<f.log_cols : (iy+1)<<f.log_cols]
		if inverse {
			f.row_fft.BitReverse(p)
			f.row_fft.InvFft(p)
		} else {
			f.row_fft.Fft(p)
			f.row_fft.BitReverse(p)
		}
		// FIXME should multiply by twiddle here row by row while it is in cache
	}

	/* transpose the matrix */
	x, f.scratch = Transpose(x, f.scratch, f.log_cols, f.log_rows)

	/* bit reverse down the rows */
	// for i := uint(0); i < f.rows; i++ {
	// 	p := x[i<<f.log_cols : i<<f.log_cols+f.rows]
	// 	f.col_fft.BitReverse(p)
	// }
	// Transpose(x, f.scratch, f.log_cols, f.log_rows)
	// for i := uint(0); i < f.cols; i++ {
	// 	p := x[i<<f.log_rows : i<<f.log_rows+f.cols]
	// 	f.row_fft.BitReverse(p)
	// }
	// Transpose(x, f.scratch, f.log_cols, f.log_rows)

	/* transpose the matrix */
	//	Transpose(x, f.scratch, f.log_cols, f.log_rows)

	/*     if (!inverse) */
	/*         bit_reverse((int)log_n, x); */

}

// A O(n log n) Four step fft
//
// Can only be use for log_n = 1..6
//
// Output is bit-reversed
func (f *FftFourStep) Fft(x []uint64) {
	f._Fft(x, false)
}

// A O(n log n) Four step fft
//
// Can only be use for log_n = 1..6
//
// Input should be bit-reversed
func (f *FftFourStep) InvFft(x []uint64) {
	f._Fft(x, true)
}
